{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Math 156 Homework 3\n",
        "## Write-up:\n",
        "**Problem 3:**\n",
        "In this first problem we write a function to train a binary logistic regression model using mini-batch SGD. The function includes the hyperparameters of batch size, learning rate (fixed), max number of iterations, x training set, and y training set. If not specified, batch size automatically defaults to a random integer between 1 and 10, since the batch size needs to be significantly smaller than the number of samples in SGD (and I would hope we have way more than 10 samples). If not specified, the learning rate is set to 0.001 and the max number of iterations is set to 10. We then use this function in the next problem.\n",
        "\n",
        "In problem 3 we also defined a quick sigmoid function which comes in handy throughout this assignment.\n",
        "\n",
        "**Problem 4**:\n",
        "In this problem we used the mini-batch sgd function we wrote in problem 3 and we use that to train the UCI breast cancer dataset. First we download the data, split up x and y, and split the data into train, test, split. Then we normalize the x-data based on the parameters from the x-training data only. Next, we report on how balanced each of the classes are. Then, we use the program from part 3 and experiment with different hyper parameters to see the best results. You yourself can implement different values and see what happens. I found that a smaller number of iterations and a smaller learning rate tended to give the best results. Finally, we reported on the model and summarized our findings.\n",
        "\n",
        "\n",
        "\n",
        "---------------------------------------------------------------\n",
        "----------------------------------------------------------\n",
        "----------------------------------------------------------\n",
        "\n",
        "#Problem 3\n",
        "\n",
        "**Instructions:** Implement a program to train a binary logistic regression model using mini-batch SGD. Use the logistic\n",
        "regression model we derived in class, corresponding to Equation (4.90) from the textbook, and where\n",
        "the feature transformation φ is the identity function.\n",
        "The program should include the following hyperparameters:\n",
        "- Batch size\n",
        "- Fixed learning rate\n",
        "- Maximum number of iterations\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sKhXKVL_AZNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# begin by importing necessary packages\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Ci4RAne3gH41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to equation 4.90 of the textbook, the gradient of the cross-entropy loss is:\n",
        "\n",
        "$∇E(w) = ∑^{N}_{n=1}(σ(w^{T}x_{n})$  $- t_{n})*x_{n}$\n",
        "\n",
        "\n",
        "First let's write a quick function for sigmoid."
      ],
      "metadata": {
        "id": "PzwKWTZGR9Vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  \"\"\"\n",
        "  Function that computes the sigmoid of a real number.\n",
        "  input: real number x\n",
        "  output: sigmoid(x)\n",
        "  \"\"\"\n",
        "  return 1 / (1 + np.exp(-np.clip(x, -100, 100)))"
      ],
      "metadata": {
        "id": "CfTu51decjq0"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's write the program that will implement mini batch SGD."
      ],
      "metadata": {
        "id": "Uj7d6MZPZXC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mini_batch_sgd(train_x, train_y, K = 10, n = 0.001, b_size = random.randint(1, 10)):\n",
        "  \"\"\"\n",
        "  Function that trains a binary logistic regression model using mini-batch SGD.\n",
        "  params:\n",
        "    train_x = x training dataset,\n",
        "    train_y = y training dataset,\n",
        "    K = max number of iterations,\n",
        "    n = fixed learning rate,\n",
        "    b_size = batch size\n",
        "  returns:\n",
        "    the optimal w by gradient descent\n",
        "  \"\"\"\n",
        "\n",
        "  # w should be an array with same dimensions as each sample\n",
        "  N = train_x.shape[0]\n",
        "  n_feats = train_x.shape[1]\n",
        "  # initialize w based on a standard gaussian distribution\n",
        "  w = [random.gauss(0, 1) for _ in range(n_feats)]\n",
        "\n",
        "  k = 0\n",
        "  while k < K:\n",
        "    #print(\"k = \", k)\n",
        "    b_indices = random.sample(range(N), b_size)\n",
        "    # compute the sum\n",
        "    mini_sum = 0\n",
        "    #print(\"w = \", w)\n",
        "    w_t = np.transpose(w)\n",
        "    for i in b_indices:\n",
        "      x_n = train_x[i]\n",
        "      y_n = train_y[i]\n",
        "      mini_sum += sigmoid(w_t @ x_n) - y_n\n",
        "\n",
        "    # now update w\n",
        "    w = w - n*mini_sum\n",
        "\n",
        "    k = k+1\n",
        "  return w"
      ],
      "metadata": {
        "id": "inws7XacQGma"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 4\n",
        "\n",
        "**A)** Download the Wisconsin Breast Cancer dataset from the UCI Machine Learning Repository or scikit-learn’s built-in datasets.\n",
        "\n",
        "Link to dataset: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html"
      ],
      "metadata": {
        "id": "pFMUu3cAgK_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we are importing from scikit-learn's datasets\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# convert to pandas dataframe\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "# drop any missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "df.head()\n",
        "# looks good"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "1hAXeplLgLyw",
        "outputId": "3637a16c-ffa2-407c-8d1d-4ac5008fb1ec"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0        17.99         10.38          122.80     1001.0          0.11840   \n",
              "1        20.57         17.77          132.90     1326.0          0.08474   \n",
              "2        19.69         21.25          130.00     1203.0          0.10960   \n",
              "3        11.42         20.38           77.58      386.1          0.14250   \n",
              "4        20.29         14.34          135.10     1297.0          0.10030   \n",
              "\n",
              "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0           0.27760          0.3001              0.14710         0.2419   \n",
              "1           0.07864          0.0869              0.07017         0.1812   \n",
              "2           0.15990          0.1974              0.12790         0.2069   \n",
              "3           0.28390          0.2414              0.10520         0.2597   \n",
              "4           0.13280          0.1980              0.10430         0.1809   \n",
              "\n",
              "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
              "0                 0.07871  ...          17.33           184.60      2019.0   \n",
              "1                 0.05667  ...          23.41           158.80      1956.0   \n",
              "2                 0.05999  ...          25.53           152.50      1709.0   \n",
              "3                 0.09744  ...          26.50            98.87       567.7   \n",
              "4                 0.05883  ...          16.67           152.20      1575.0   \n",
              "\n",
              "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
              "0            0.1622             0.6656           0.7119                0.2654   \n",
              "1            0.1238             0.1866           0.2416                0.1860   \n",
              "2            0.1444             0.4245           0.4504                0.2430   \n",
              "3            0.2098             0.8663           0.6869                0.2575   \n",
              "4            0.1374             0.2050           0.4000                0.1625   \n",
              "\n",
              "   worst symmetry  worst fractal dimension  target  \n",
              "0          0.4601                  0.11890       0  \n",
              "1          0.2750                  0.08902       0  \n",
              "2          0.3613                  0.08758       0  \n",
              "3          0.6638                  0.17300       0  \n",
              "4          0.2364                  0.07678       0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63e196b2-2498-4af6-95ea-7e8c307afda7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63e196b2-2498-4af6-95ea-7e8c307afda7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-63e196b2-2498-4af6-95ea-7e8c307afda7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-63e196b2-2498-4af6-95ea-7e8c307afda7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b238303b-263e-4d96-867e-033a46b0c735\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b238303b-263e-4d96-867e-033a46b0c735')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b238303b-263e-4d96-867e-033a46b0c735 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**B)** Split the dataset into train, validation, and test sets."
      ],
      "metadata": {
        "id": "kj2xMPogdXeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary packages\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# now do test-train-val split\n",
        "X = df.drop(\"target\", axis=1)\n",
        "y = df[\"target\"]\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "# 20% test, 10% validation, 70% training, just like in the last homework.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1)\n",
        "\n",
        "# normalize the data based only on statistics from train dataset\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_val = scaler.transform(X_val)"
      ],
      "metadata": {
        "id": "aSrF8wzAhdgi"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**C)** Report the size of each class in your training (+ validation) set.\n",
        "\n",
        "External source for the following code:\n",
        "https://stackoverflow.com/questions/28663856/how-do-i-count-the-occurrence-of-a-certain-item-in-an-ndarray"
      ],
      "metadata": {
        "id": "zVYSeA_HiU3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# determine the number of unique items in each class for y_train, y_val, and y_test\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "y_train_dict = dict(zip(unique, counts))\n",
        "\n",
        "unique, counts = np.unique(y_val, return_counts=True)\n",
        "y_val_dict = dict(zip(unique, counts))\n",
        "\n",
        "unique, counts = np.unique(y_test, return_counts=True)\n",
        "y_test_dict = dict(zip(unique, counts))\n",
        "\n",
        "# report\n",
        "print(\"Training: \\nNumber of 0s:\", y_train_dict[0], \"\\nNumber of 1s:\", y_train_dict[1] )\n",
        "print(\"\\nValidation: \\nNumber of 0s:\", y_val_dict[0], \"\\nNumber of 1s:\", y_val_dict[1] )\n",
        "print(\"\\nTesting: \\nNumber of 0s:\", y_test_dict[0], \"\\nNumber of 1s:\", y_test_dict[1] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAdijHNfh9vN",
        "outputId": "abfd88ec-d7ad-4969-f0f7-bdb5e70ba867"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training: \n",
            "Number of 0s: 151 \n",
            "Number of 1s: 247\n",
            "\n",
            "Validation: \n",
            "Number of 0s: 19 \n",
            "Number of 1s: 38\n",
            "\n",
            "Testing: \n",
            "Number of 0s: 42 \n",
            "Number of 1s: 72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**D)** Train a binary logistic regression model using your implementation from problem 3. Initialize\n",
        "the model weights randomly, sampling from a standard Gaussian distribution. Experiment with\n",
        "different choices of fixed learning rate and batch size.\n",
        "\n",
        "**Note** You can input any hyperparameters that you want here! I experimented with multiple different values of iterations, learning rate, and batch size."
      ],
      "metadata": {
        "id": "cVNhB-Ieds9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the model weights have already been randomly initialized following the gaussian distribution in the function.\n",
        "\n",
        "# max_iter = 20, learning rate = 0.001, batch size = 3\n",
        "w_calc = mini_batch_sgd(X_train, y_train, 20, 0.001, 3)\n",
        "\n",
        "# final w\n",
        "print(w_calc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLbjlhlGZlff",
        "outputId": "1e0b4a58-0144-43a5-c448-35edd84b0ad2"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.27672406  1.5941939   0.22880185 -1.23857881 -0.55822384  1.17844736\n",
            " -2.7276666  -0.61180367 -0.48017023 -0.25713534  2.23427245 -0.22106592\n",
            " -0.71312025 -1.73851096  0.50458885 -1.33272628  0.01084392  0.20238108\n",
            "  0.63894467 -1.19257141 -0.98178075 -0.14108592 -0.0492283   0.13253185\n",
            "  0.34299944  1.62218555 -1.01270415 -0.44116613  0.35376204 -0.15318822]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**E)** Use the trained model to report the performance of the model on the test set. For evaluation\n",
        "metrics, use accuracy, precision, recall, and F1-score."
      ],
      "metadata": {
        "id": "PDVywEy2d7qL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict values\n",
        "y_pred_test = sigmoid(X_test @ w_calc)\n",
        "\n",
        "# convert the probabilities to binary values\n",
        "y_pred_test = np.array([1 if _ >= 0.5 else 0 for _ in y_pred_test])\n",
        "\n",
        "print(y_pred_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEXfKtogagFy",
        "outputId": "db959ba3-1e67-409e-e383-7764560091ee"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0\n",
            " 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0\n",
            " 1 0 1 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation time\n",
        "# import necessary packages\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# evaluate each of the metrics\n",
        "acc = accuracy_score(y_test, y_pred_test)\n",
        "precis = precision_score(y_test, y_pred_test)\n",
        "recall = recall_score(y_test, y_pred_test)\n",
        "f1_score = f1_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"Accuracy:\", acc, \"\\n \\nPrecision:\", precis, \"\\n \\nRecall:\", recall, \"\\n \\nF1 Score:\", f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ1trTi5bt1q",
        "outputId": "17e622b5-d663-4a28-dc8b-bd3ba7de9a75"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8157894736842105 \n",
            " \n",
            "Precision: 0.8591549295774648 \n",
            " \n",
            "Recall: 0.8472222222222222 \n",
            " \n",
            "F1 Score: 0.8531468531468531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**E)** Summarize your findings.\n",
        "\n",
        "\n",
        "In summary, I experimented with many different values of number of iterations, batch size, and step size. I found that a small step size was good (n = 0.001) so that we didn't overshoot in gradient descent, and surprisingly a smaller number of iterations gave a better result as well (20 iterations had better results than 500).\n",
        "\n",
        "Overall findings:\n",
        "- **Accuracy:** 82%\n",
        "- **Precision:** 86%\n",
        "- **Recall:** 85%\n",
        "- **F1 score:** 85%\n",
        "\n",
        "This model can hence semi-accurately predict breast cancer based on the features on unseen data."
      ],
      "metadata": {
        "id": "qE0i58_ZekXo"
      }
    }
  ]
}
